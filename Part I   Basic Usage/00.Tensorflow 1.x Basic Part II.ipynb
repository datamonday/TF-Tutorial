{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.数据读取\n",
    "## 3.1文件读取流程\n",
    "多线程+队列\n",
    "\n",
    "1. QueueRunner：基于队列的输入管道从TensorFlow图形开头的文件读取数据。\n",
    "2. Feeding：每运行一步时，python代码提供数据。\n",
    "3. 预加载数据：TensorFlow图中的张量包含所有的数据（对于小数据集）。\n",
    "\n",
    "### 3.1.1 通用文件读取流程\n",
    "- 1）第一阶段：构造文件名队列\n",
    "- 2）第二阶段：读取与解码\n",
    "- 3）第三阶段：批处理并手动开启线程\n",
    "注意：这些操作需要启动运行这些队列操作的线程，以便我们在进行文件读取的过程中能够顺利进行入队出队操作。\n",
    "\n",
    "1. 构造文件名队列\n",
    "将需要读取的文件的文件名放入文件名队列。\n",
    "~~tf.train.string_input_producer(string_tensor,shuffle=True)~~已弃用！\n",
    "- string_tensor：含有文件名+路径的1阶张量；\n",
    "- num_epochs：过几遍数据\n",
    "- return 文件队列\n",
    "\n",
    "替换为：\n",
    "tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)\n",
    "\n",
    "2. 读取与解码\n",
    "- 1）读取文件内容\n",
    "  - tf.TextLineReader():读取问问文件逗号分隔值（CSV）格式，默认按行读取\n",
    "    return：读取器实例\n",
    "  - tf.WholeFileReader():读取图片\n",
    "    return：读取器实例\n",
    "  - tf.FixedLengthRecordReaders(record_bytes):二进制文件\n",
    "    要读取每个记录是固定数量字节的二进制文件\n",
    "    record_bytes:整型，指定每次读取（一个样本）的字节数\n",
    "    return：读取器实例\n",
    "  - tf.TFRecordReader():读取TFRecords文件\n",
    "    return：读取器实例\n",
    "  它们有共同的读取方法:key,value = read(file_queue)，并且都会返回一个Tensor元组。\n",
    "  - key：文件名\n",
    "  - value：一个样本\n",
    "  由于默认只会读取一个样本，所以如果想要进行批处理，需要使用tf.train.batch或tf.train.shuffle_batch进行批处理操作，便于以后制定每批次多个样本的训练。\n",
    "  \n",
    "- 2）内容解码\n",
    "读取不同类型的文件，也应该对读取到的不同类型的内容进行相应的解码操作，解码成统一的Tensor格式。解码阶段，默认所有的内容都解码成tf.uint8类型，如果要转换成指定类型，则需要使用tf.cast()进行相应的转换。\n",
    "  - tf.decode_csv：解码文本文件内容\n",
    "  - tf.image.decode_jpeg(contents)\n",
    "    - 将jpeg编的图像解码为uint8张量\n",
    "    - return：uint8张量，3-D形状[height,width,channels]\n",
    "  - tf.image.decode_png(contents)\n",
    "    - 将png编码的图像解码为uint8张量\n",
    "    - return：张量类型，3-D形状[height,width,channels]\n",
    "  - tf.decode_raw：解码二进制文件内容\n",
    "    - 与tf.FixedLengthRecordReader搭配使用，二进制读取为uint8类型\n",
    "    \n",
    "    \n",
    "3. 批处理\n",
    "解码之后，可以直接获取默认的一个样本内容。但如果想要获取多个样本，需要加入到新的队列进行批处理。\n",
    "\n",
    "~~tf.compat.v1.train.batch(tensors, batch_size, num_threads=1, capacity=32, name=None)~~ 已弃用！\n",
    "\n",
    "- 读取指定大小（个数）的张量；\n",
    "- tensors：可以是包含张量的列表，批处理的内容放到列表中\n",
    "- batch_size：从队列中读取的批处理的大小\n",
    "- num_threads：进入队列的线程数\n",
    "- capacity：整数，队列中元素的最大数量\n",
    "- return ：tensors\n",
    "\n",
    "替换为：\n",
    "tf.data.Dataset.batch(batch_size, drop_remainder=False)\n",
    "- batch_size：一个tf.int64标量tf.Tensor，表示此数据集要在单个批次中合并的连续元素的数量。\n",
    "- drop_remainder：（可选）一个tf.bool标量tf.Tensor，表示在batch_size元素少于元素的情况下是否应删除最后一批 ；默认行为是不删除较小的批次。\n",
    "\n",
    "~~tf.train.shuffle_batch~~ 已弃用！\n",
    "替换为：\n",
    "tf.data.Dataset.shuffle(\n",
    "    buffer_size, seed=None, reshuffle_each_iteration=None\n",
    ")\n",
    "\n",
    "- buffer_size：一个tf.int64标量tf.Tensor，表示此数据集中要从中采样新数据集的元素数。\n",
    "- seed：（可选）tf.int64标量tf.Tensor，表示将用于创建分布的随机种子。请参阅 tf.compat.v1.set_random_seed。\n",
    "- reshuffle_each_iteration：（可选）布尔值，如果为true，则表示每次迭代数据集时都应进行伪随机重排。（默认为True）\n",
    "\n",
    "### 3.1.2 线程操作\n",
    "tf.compat.v1.train.QueueRunner(\n",
    "    queue=None, enqueue_ops=None, close_op=None, cancel_op=None,\n",
    "    queue_closed_exception_types=None, queue_runner_def=None, import_scope=None\n",
    ")\n",
    "\n",
    "队列是一种方便的TensorFlow机制，可使用多个线程异步计算张量。例如，在规范的“输入读取器（Input Reader）”设置中，一组线程在队列中生成文件名。第二组线程从文件中读取记录，对其进行处理，并将张量排入第二个队列；第三组线程使这些输入记录出队以构造批次并通过训练操作运行它们。\n",
    "每个QueueRunner都负责一个阶段，tf.train.start_queue_runners 函数会要求图中的每个QueueRunner启动他的运行队列操作的线程。（这些操作需要在会话中开启）\n",
    "\n",
    "tf.compat.v1.train.start_queue_runners(\n",
    "    sess=None, coord=None, daemon=True, start=True,\n",
    "    collection=tf.GraphKeys.QUEUE_RUNNERS\n",
    ")\n",
    "- sess：Session用于运行队列操作。默认为默认会话。\n",
    "- coord：可选，Coordinator用于协调启动的线程。\n",
    "- daemon：线程是否应标记为daemons，表示它们不阻止程序退出。\n",
    "- start：设置为False仅创建线程，而不启动它们。\n",
    "- collection：一个GraphKey指定图形集合以从中获取队列运行器。默认为GraphKeys.QUEUE_RUNNERS。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 图片数据\n",
    "\n",
    "### 3.2.1 图像基本知识\n",
    "- 特征提取\n",
    "  文本 -> 数值(二维数组shape(n_samples,m_faetures))\n",
    "  字典 -> 数值(二维数组shape(n_samples,m_faetures))\n",
    "  图片 -> \n",
    "  \n",
    "1. 图片三要素\n",
    "组成一张图片特征值是所有的像素值，图片有三个维度长、宽、通道(channel)数\n",
    "- 1）灰度图[长，宽，1]\n",
    "  每一个像素点为[0,255]的数值，越接近于0，图片越黑。\n",
    "- 2）彩色图[长，宽，3]\n",
    "  每个像素点用3个[0,255]的数值描述。\n",
    "\n",
    "2. 张量的形状\n",
    "Tensor(指令名称，shape，dtype)\n",
    "一张图片 shape = (height, width, channerls)\n",
    "多张图片 shape = (batch, height, width, channels)\n",
    "\n",
    "### 3.2.2 图片特征值处理\n",
    "为什么要缩放图片到统一大小？\n",
    "在进行图像识别的时候，每个图片样本的特征数量要保持相同。所以需要将所有图片张量大小统一装换。另一方面，如果图片的像素量太大，通过这种方法适当减少像素的数量，减少训练的计算开销。\n",
    "  \n",
    "~~tf.image.resize_images(images,size)~~ 已弃用！\n",
    "替换为：\n",
    "tf.image.resize(\n",
    "    images, size, method=ResizeMethod.BILINEAR, preserve_aspect_ratio=False,\n",
    "    antialias=False, name=None\n",
    ")\n",
    "\n",
    "- images：形状的4-D张量[batch, height, width, channels]或形状的3-D张量[height, width, channels]。\n",
    "- size：2个元素的一维int32张量：new_height, new_width。图片的新尺寸。\n",
    "- method：ResizeMethod。默认为bilinear。\n",
    "- preserve_aspect_ratio：是否保留长宽比。如果设置了此项，则将images在size保留原始图像的纵横比的同时将其调整为适合的尺寸。如果图像size大于当前尺寸，则按比例放大图像 image。默认为False。\n",
    "- antialias：对图像进行下采样时是否使用抗混叠滤波器。\n",
    "- name：此操作的名称（可选）。\n",
    "\n",
    "### 3.2.3 数据格式\n",
    "- 存储：uint(节约空间)\n",
    "- 矩阵运算：float32(提高精度)\n",
    "\n",
    "编程过程中，要注意转换！\n",
    "\n",
    "### 3.2.4 案例：图片读取\n",
    "- 1）第一阶段：构造文件名队列\n",
    "- 2）第二阶段：读取与解码\n",
    "- 3）第三阶段：批处理并手动开启线程 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b25c7f1d1cd6>:12: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-2-b25c7f1d1cd6>:17: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n",
      "image_resized_new:\n",
      " Tensor(\"resize/Squeeze:0\", shape=(200, 200, 3), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-2-b25c7f1d1cd6>:34: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From <ipython-input-2-b25c7f1d1cd6>:41: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      " image_new:\n",
      " [[[ 86  67  71]\n",
      "  [ 84  65  69]\n",
      "  [ 80  61  65]\n",
      "  ...\n",
      "  [ 48  33  38]\n",
      "  [ 49  34  39]\n",
      "  [ 50  35  40]]\n",
      "\n",
      " [[ 80  61  65]\n",
      "  [ 79  60  64]\n",
      "  [ 76  57  61]\n",
      "  ...\n",
      "  [ 54  39  44]\n",
      "  [ 55  40  45]\n",
      "  [ 56  41  46]]\n",
      "\n",
      " [[ 78  59  63]\n",
      "  [ 77  58  62]\n",
      "  [ 76  57  61]\n",
      "  ...\n",
      "  [ 55  40  45]\n",
      "  [ 55  40  45]\n",
      "  [ 57  42  47]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 56  36  47]\n",
      "  [ 50  30  41]\n",
      "  [ 48  28  37]\n",
      "  ...\n",
      "  [213 201 189]\n",
      "  [213 201 189]\n",
      "  [212 200 188]]\n",
      "\n",
      " [[ 58  38  49]\n",
      "  [ 53  33  44]\n",
      "  [ 52  32  41]\n",
      "  ...\n",
      "  [214 202 190]\n",
      "  [213 201 189]\n",
      "  [212 200 188]]\n",
      "\n",
      " [[ 67  47  58]\n",
      "  [ 62  42  53]\n",
      "  [ 61  41  50]\n",
      "  ...\n",
      "  [215 203 191]\n",
      "  [214 202 190]\n",
      "  [213 201 189]]]\n",
      "image_resized_new:\n",
      " [[[ 86.        67.        71.      ]\n",
      "  [ 78.515     59.515     63.515   ]\n",
      "  [ 75.979996  59.98      60.98    ]\n",
      "  ...\n",
      "  [ 50.880127  36.880127  36.39511 ]\n",
      "  [ 56.900208  42.900208  42.900208]\n",
      "  [ 48.504974  33.504974  38.504974]]\n",
      "\n",
      " [[ 78.25      59.25      63.25    ]\n",
      "  [ 75.44312   56.443127  60.443127]\n",
      "  [ 71.2575    55.2575    56.2575  ]\n",
      "  ...\n",
      "  [ 53.205738  38.755127  40.046333]\n",
      "  [ 61.525208  46.64896   49.277702]\n",
      "  [ 54.93812   39.93812   44.93812 ]]\n",
      "\n",
      " [[ 80.75      61.75      65.75    ]\n",
      "  [ 79.01      60.010002  64.01    ]\n",
      "  [ 67.795     51.795002  52.795002]\n",
      "  ...\n",
      "  [ 55.660095  40.660095  45.160095]\n",
      "  [ 65.65021   50.650208  57.13524 ]\n",
      "  [ 58.        43.        48.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 55.625     35.625     46.625   ]\n",
      "  [ 51.125     31.619999  39.135002]\n",
      "  [ 41.165     25.165     25.195002]\n",
      "  ...\n",
      "  [213.58685  201.58685  189.58685 ]\n",
      "  [217.25998  205.25998  193.25998 ]\n",
      "  [214.12003  202.12003  190.12003 ]]\n",
      "\n",
      " [[ 60.5       40.5       51.5     ]\n",
      "  [ 51.997498  32.4925    40.0075  ]\n",
      "  [ 47.0275    31.0275    31.0575  ]\n",
      "  ...\n",
      "  [215.       203.       191.      ]\n",
      "  [214.74002  202.74002  190.74002 ]\n",
      "  [213.       201.       189.      ]]\n",
      "\n",
      " [[ 59.125     39.125     50.125   ]\n",
      "  [ 55.22875   35.723747  43.238747]\n",
      "  [ 56.1475    40.1475    40.1775  ]\n",
      "  ...\n",
      "  [212.75     200.75     188.75    ]\n",
      "  [213.00125  201.00125  189.00125 ]\n",
      "  [213.62003  201.62003  189.62003 ]]]\n",
      "image_batch_new:\n",
      " [[[[140.       134.       108.      ]\n",
      "   [140.       134.       109.45    ]\n",
      "   [140.       134.       110.      ]\n",
      "   ...\n",
      "   [113.        85.        61.      ]\n",
      "   [113.        85.        61.      ]\n",
      "   [113.        85.        61.      ]]\n",
      "\n",
      "  [[140.       134.       109.46    ]\n",
      "   [140.       134.       109.8515  ]\n",
      "   [140.       134.       110.      ]\n",
      "   ...\n",
      "   [113.        85.        61.      ]\n",
      "   [113.        85.        61.      ]\n",
      "   [113.        85.        61.      ]]\n",
      "\n",
      "  [[140.       133.54     112.92    ]\n",
      "   [140.       133.6665   112.369995]\n",
      "   [140.       134.       110.92    ]\n",
      "   ...\n",
      "   [113.        85.        61.      ]\n",
      "   [113.        85.        61.      ]\n",
      "   [113.        85.        61.      ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[187.04999  181.04999  159.04999 ]\n",
      "   [188.87999  182.87999  160.87999 ]\n",
      "   [192.97     186.97     164.97    ]\n",
      "   ...\n",
      "   [135.35164  118.559875  92.14662 ]\n",
      "   [128.82007  109.619995  81.79001 ]\n",
      "   [134.31226  112.76227   82.88453 ]]\n",
      "\n",
      "  [[192.08002  186.08002  164.08002 ]\n",
      "   [193.26501  187.26501  165.26501 ]\n",
      "   [195.197    189.197    167.197   ]\n",
      "   ...\n",
      "   [137.4944   119.844376  96.749405]\n",
      "   [131.20007  111.45999   86.287   ]\n",
      "   [136.29153  114.59305   86.271576]]\n",
      "\n",
      "  [[186.       180.       158.      ]\n",
      "   [190.9      184.9      162.9     ]\n",
      "   [200.7      194.7      172.7     ]\n",
      "   ...\n",
      "   [136.47504  118.650024  97.44549 ]\n",
      "   [137.55002  117.349945  93.49844 ]\n",
      "   [137.275    115.45001   88.17502 ]]]\n",
      "\n",
      "\n",
      " [[[223.       224.       218.      ]\n",
      "   [223.       224.       218.      ]\n",
      "   [222.       223.       217.      ]\n",
      "   ...\n",
      "   [229.2699   233.2699   236.2699  ]\n",
      "   [237.76025  238.85016  242.82019 ]\n",
      "   [243.98502  242.       247.      ]]\n",
      "\n",
      "  [[219.01     220.01     214.01    ]\n",
      "   [220.52     221.52     215.52    ]\n",
      "   [222.03     223.03     217.03    ]\n",
      "   ...\n",
      "   [234.80988  238.80988  241.80988 ]\n",
      "   [234.42993  238.42993  241.42993 ]\n",
      "   [244.515    247.       250.505   ]]\n",
      "\n",
      "  [[218.99     219.99     213.99    ]\n",
      "   [219.015    220.015    214.015   ]\n",
      "   [221.04     222.04     216.04    ]\n",
      "   ...\n",
      "   [235.18083  239.18083  242.18083 ]\n",
      "   [233.93036  237.93036  240.93036 ]\n",
      "   [234.04015  239.04001  242.04001 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[213.51498  213.48502  219.      ]\n",
      "   [208.52951  209.97003  213.96228 ]\n",
      "   [208.46954  211.01547  212.36502 ]\n",
      "   ...\n",
      "   [212.       211.       206.      ]\n",
      "   [213.       213.       205.      ]\n",
      "   [216.       213.       208.      ]]\n",
      "\n",
      "  [[220.98004  214.01996  222.00998 ]\n",
      "   [213.955    209.02979  214.97481 ]\n",
      "   [210.94     209.01936  211.84033 ]\n",
      "   ...\n",
      "   [212.       211.       206.      ]\n",
      "   [213.       213.       205.      ]\n",
      "   [216.       213.       208.      ]]\n",
      "\n",
      "  [[210.48508  215.50497  222.      ]\n",
      "   [209.41008  215.43755  218.39241 ]\n",
      "   [205.52502  210.56497  208.9397  ]\n",
      "   ...\n",
      "   [211.       210.48225  204.0582  ]\n",
      "   [212.97003  212.97003  204.97003 ]\n",
      "   [216.       212.01498  208.98502 ]]]\n",
      "\n",
      "\n",
      " [[[137.       124.       115.      ]\n",
      "   [139.       126.       117.      ]\n",
      "   [106.        93.        84.      ]\n",
      "   ...\n",
      "   [193.       179.       164.5     ]\n",
      "   [128.       119.       102.      ]\n",
      "   [237.5      226.5      196.5     ]]\n",
      "\n",
      "  [[121.56     111.17     101.3     ]\n",
      "   [146.045    135.655    125.785   ]\n",
      "   [101.26      90.87      81.      ]\n",
      "   ...\n",
      "   [173.69     159.69     145.19    ]\n",
      "   [131.13     119.13     103.13    ]\n",
      "   [242.74     230.       198.26    ]]\n",
      "\n",
      "  [[116.       109.48      97.74    ]\n",
      "   [153.89     147.37     135.63    ]\n",
      "   [110.74     104.22      92.48    ]\n",
      "   ...\n",
      "   [154.58     140.58     126.08    ]\n",
      "   [122.3      110.3       94.3     ]\n",
      "   [237.52     221.04     190.78    ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[228.56006  225.56006  210.56006 ]\n",
      "   [244.43994  241.43994  226.43994 ]\n",
      "   [238.60999  235.60999  220.60999 ]\n",
      "   ...\n",
      "   [108.       102.91498  100.71997 ]\n",
      "   [135.43994  119.2699   116.65991 ]\n",
      "   [137.71997  113.80499  105.5     ]]\n",
      "\n",
      "  [[236.       233.       218.      ]\n",
      "   [237.10999  234.10999  219.10999 ]\n",
      "   [237.26001  234.26001  219.26001 ]\n",
      "   ...\n",
      "   [103.19995   97.19995   94.69995 ]\n",
      "   [122.69995  104.69995  102.69995 ]\n",
      "   [133.34998  113.869995 104.609985]]\n",
      "\n",
      "  [[232.60999  229.60999  214.60999 ]\n",
      "   [236.5      233.5      218.5     ]\n",
      "   [241.39001  238.39001  223.39001 ]\n",
      "   ...\n",
      "   [ 95.30499   89.30499   86.80499 ]\n",
      "   [114.869995  99.869995  96.869995]\n",
      "   [129.67499  113.065    102.935   ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[241.       218.       228.      ]\n",
      "   [203.       180.       190.      ]\n",
      "   [210.       187.       197.      ]\n",
      "   ...\n",
      "   [188.       198.       210.      ]\n",
      "   [197.       200.       207.      ]\n",
      "   [185.       183.       188.      ]]\n",
      "\n",
      "  [[241.       218.       228.      ]\n",
      "   [203.       180.       190.      ]\n",
      "   [209.485    186.485    196.485   ]\n",
      "   ...\n",
      "   [189.03     198.       208.515   ]\n",
      "   [196.       197.97     203.94    ]\n",
      "   [171.85     169.85     172.85    ]]\n",
      "\n",
      "  [[240.       217.       227.      ]\n",
      "   [202.       179.       189.      ]\n",
      "   [208.97     185.97     195.97    ]\n",
      "   ...\n",
      "   [187.94     196.94     205.94    ]\n",
      "   [191.94     192.88     197.88    ]\n",
      "   [165.03     160.97     161.94    ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[138.        48.        58.      ]\n",
      "   [126.        36.        46.      ]\n",
      "   [124.        34.        44.      ]\n",
      "   ...\n",
      "   [ 84.81995   24.545013  40.454987]\n",
      "   [ 91.90997   29.090027  48.      ]\n",
      "   [ 89.90997   23.090027  43.545013]]\n",
      "\n",
      "  [[134.12      42.179993  53.149994]\n",
      "   [122.119995  30.179993  41.149994]\n",
      "   [122.06      30.119995  41.089996]\n",
      "   ...\n",
      "   [ 93.79001   24.970001  43.910004]\n",
      "   [100.76001   28.970001  50.910004]\n",
      "   [ 95.850006  22.        44.940002]]\n",
      "\n",
      "  [[144.84985   50.394897  61.879883]\n",
      "   [133.33484   38.879883  50.36487 ]\n",
      "   [133.33484   38.879883  50.36487 ]\n",
      "   ...\n",
      "   [102.93994   28.96997   49.454956]\n",
      "   [110.3949    32.96997   56.93994 ]\n",
      "   [106.87988   26.454956  51.424927]]]\n",
      "\n",
      "\n",
      " [[[180.       179.       159.      ]\n",
      "   [196.95     195.95     175.95    ]\n",
      "   [190.25     189.25     169.25    ]\n",
      "   ...\n",
      "   [119.57498   97.        54.275055]\n",
      "   [123.        95.95001   53.099976]\n",
      "   [124.        94.        57.049988]]\n",
      "\n",
      "  [[178.       177.       157.      ]\n",
      "   [187.5545   186.5545   166.5545  ]\n",
      "   [192.012    191.012    171.012   ]\n",
      "   ...\n",
      "   [120.72858   98.153595  55.428646]\n",
      "   [122.02      94.97001   52.119976]\n",
      "   [123.02      93.02      56.06999 ]]\n",
      "\n",
      "  [[181.92     180.92     160.92    ]\n",
      "   [175.2      174.2      154.2     ]\n",
      "   [179.06999  178.06999  158.06999 ]\n",
      "   ...\n",
      "   [115.48989   92.91491   50.189964]\n",
      "   [121.04      93.99001   51.139977]\n",
      "   [122.04      92.04      55.08999 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[227.53998  237.53998  238.53998 ]\n",
      "   [216.24246  226.24246  227.24246 ]\n",
      "   [205.59897  215.59897  216.59897 ]\n",
      "   ...\n",
      "   [254.       254.       254.      ]\n",
      "   [254.       254.       254.      ]\n",
      "   [254.       254.       254.      ]]\n",
      "\n",
      "  [[221.23984  231.23984  232.23984 ]\n",
      "   [211.56891  221.56891  222.56891 ]\n",
      "   [214.39992  224.39992  225.39992 ]\n",
      "   ...\n",
      "   [254.       254.       254.      ]\n",
      "   [254.       254.       254.      ]\n",
      "   [254.       254.       254.      ]]\n",
      "\n",
      "  [[182.84009  192.84009  193.84009 ]\n",
      "   [195.95047  205.95047  206.95047 ]\n",
      "   [196.73102  206.73102  207.73102 ]\n",
      "   ...\n",
      "   [254.       254.       254.      ]\n",
      "   [254.       254.       254.      ]\n",
      "   [254.       254.       254.      ]]]\n",
      "\n",
      "\n",
      " [[[116.        88.        76.      ]\n",
      "   [122.99      94.99      82.99    ]\n",
      "   [124.        94.        83.      ]\n",
      "   ...\n",
      "   [121.514984  94.485016  80.      ]\n",
      "   [121.99002   94.00998   80.01996 ]\n",
      "   [117.99005   92.504974  82.00995 ]]\n",
      "\n",
      "  [[118.87      90.87      79.74    ]\n",
      "   [126.235     98.235     87.105   ]\n",
      "   [126.87      96.87      85.87    ]\n",
      "   ...\n",
      "   [124.70302   97.67305   83.188034]\n",
      "   [121.10136   93.10136   79.121315]\n",
      "   [117.495026  90.26129   79.32694 ]]\n",
      "\n",
      "  [[117.52      90.        82.74    ]\n",
      "   [124.1437    96.7524    88.373695]\n",
      "   [125.52      96.9926    86.0174  ]\n",
      "   ...\n",
      "   [128.99498  101.96502   87.48    ]\n",
      "   [121.4327    93.4327    79.4327  ]\n",
      "   [113.88632   85.14632   71.66632 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[128.87988   90.87988   78.65991 ]\n",
      "   [134.56712   97.17101   83.26518 ]\n",
      "   [125.0222    88.22997   73.41831 ]\n",
      "   ...\n",
      "   [106.33008  114.33008  127.33008 ]\n",
      "   [ 98.38393  106.38393  119.38393 ]\n",
      "   [100.69197  106.69197  120.07592 ]]\n",
      "\n",
      "  [[129.08008   91.08008   80.08008 ]\n",
      "   [138.93878  100.938774  87.938774]\n",
      "   [137.35269   99.35269   86.35269 ]\n",
      "   ...\n",
      "   [108.71506  116.71506  129.71506 ]\n",
      "   [101.517426 109.517426 122.517426]\n",
      "   [101.495026 107.495026 121.495026]]\n",
      "\n",
      "  [[137.65002   99.650024  88.650024]\n",
      "   [142.16064  104.16064   91.16064 ]\n",
      "   [141.76129  103.76129   90.76129 ]\n",
      "   ...\n",
      "   [109.90308  117.90308  130.90308 ]\n",
      "   [104.       112.       125.      ]\n",
      "   [102.495026 108.495026 122.495026]]]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def picture_read():\n",
    "    \"\"\"\n",
    "    图片读取案例\n",
    "    \"\"\"\n",
    "    filename = os.listdir(\"D:/AliyunEDU/cats vs dogs\")\n",
    "    # 拼接路径+文件名\n",
    "    file_list = [os.path.join(\"D:/AliyunEDU/cats vs dogs/\",file) for file in filename]\n",
    "    #print(\"file_list:{}\".format(fiel_list))\n",
    "    \n",
    "    # 1.构造文件名队列\n",
    "    file_queue = tf.compat.v1.train.string_input_producer(file_list)\n",
    "    #tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)\n",
    "\n",
    "    # 2.读取与解码\n",
    "    ## 读取阶段 uint8\n",
    "    reader = tf.compat.v1.WholeFileReader()\n",
    "    # key为文件名，value为一张图片原始编码形式\n",
    "    key,value = reader.read(file_queue)\n",
    "    #print(\" key:{} \\n value: {} \\n\" .format(key,value))\n",
    "    \n",
    "    ## 解码阶段 变为float32\n",
    "    image = tf.compat.v1.image.decode_jpeg(value)\n",
    "    #print(\"image:\\n\",image)\n",
    "    \n",
    "    # 图像的形状，类型修改\n",
    "    image_resized = tf.compat.v1.image.resize_images(image,[200,200])\n",
    "    \n",
    "    ## 静态形状自改\n",
    "    image_resized.set_shape(shape=[200,200,3])\n",
    "    print(\"image_resized_new:\\n\",image_resized)\n",
    "    \n",
    "    # 3.批处理\n",
    "    image_batch = tf.compat.v1.train.batch([image_resized], batch_size=100, num_threads=1, capacity=100)\n",
    "    \n",
    "    # 开启会话\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        # 开启线程\n",
    "        ## ①线程协调员\n",
    "        coord = tf.compat.v1.train.Coordinator()\n",
    "        threads = tf.compat.v1.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        \n",
    "        key_new,value_new,image_new,image_resized_new,image_batch_new = sess.run([key, value, image, image_resized, image_batch])\n",
    "        #print(\" key_new:{}\\n value_new:{}\\n\".format(key_new,value_new))\n",
    "        \n",
    "        # 查看解码后的图片的值\n",
    "        print(\" image_new:\\n\",image_new)\n",
    "        # 查看resize之后的数据\n",
    "        print(\"image_resized_new:\\n\",image_resized_new)\n",
    "        # 查看批处理之后的数据\n",
    "        print(\"image_batch_new:\\n\",image_batch_new)\n",
    "        \n",
    "        ## ②回收线程\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    \n",
    "picture_read()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 二进制文件读取\n",
    "### 3.3.1 CIFAR-10数据集说明\n",
    "二进制版本数据集的格式：<1×标签> <3072×像素>\n",
    "第一个字节是第一个图像的标签，它是一个0-9范围内的数字。接下来的3072个字节是图像像素的值。前1024个字节是红色通道值，下1024个绿色，最后1024个蓝色。值以行优先顺序存储，因此前32个字节是图像第一行的红色通道值。\n",
    "\n",
    "### 3.3.2 二进制数据读取\n",
    "流程分析：\n",
    "1. 构造文件名队列\n",
    "2. 读取与解码\n",
    "  reader = tf.compat.v1.FixedLengthRecordReader(3073)\n",
    "  key,value = reader.read(file_queue)\n",
    "  decoded = tf.decode_raw(value, tf.uint8)\n",
    "  - 对tensor对象进行切片以截取标签和图片\n",
    "  - 改变图像的形状（tensorflow图像的表示习惯收为通道数、长、宽）\n",
    "  - 转置将图片的顺序调整为height、width、channels（reshape之后涉及到NHWC与NCHW转换的问题）ndarray.T 转置 行变列，列变行\n",
    "    \n",
    "3. 批处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10数据：\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-e786a0eb8600>:22: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "key:\n",
      "Tensor(\"ReaderReadV2_1:0\", shape=(), dtype=string)\n",
      " value:\n",
      "Tensor(\"ReaderReadV2_1:1\", shape=(), dtype=string)\n",
      "\n",
      "image_reshaped:Tensor(\"Reshape:0\", shape=(3, 32, 32), dtype=uint8)\n",
      " image_tansposed:Tensor(\"transpose:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "\n",
      "Tensor(\"batch_1:0\", shape=(100, 1), dtype=uint8)\n",
      "decoded_new:\n",
      " [  8  98  91 ... 125 132 138]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "class Cifar(object):\n",
    "    def __init__(self):\n",
    "        # 初始化操作\n",
    "        self.height = 32\n",
    "        self.width = 32\n",
    "        self.channels = 3\n",
    "        \n",
    "        # 字节数\n",
    "        self.image_bytes = self.height * self.width * self.channels\n",
    "        self.label_bytes = 1\n",
    "        self.all_bytes = self.label_bytes + self.image_bytes\n",
    "        \n",
    "    def read_and_decode(self,file_list):\n",
    "        # 1.构造文件名队列\n",
    "        file_queue = tf.compat.v1.train.string_input_producer(file_list)\n",
    "        \n",
    "        # 2.读取与解码\n",
    "        ## 读取阶段\n",
    "        reader = tf.compat.v1.FixedLengthRecordReader(self.all_bytes)\n",
    "        key,value = reader.read(file_queue)\n",
    "        print(\"key:\\n{}\\n value:\\n{}\\n\".format(key,value))\n",
    "        \n",
    "        ## 解码阶段\n",
    "        decoded = tf.compat.v1.decode_raw(value, tf.uint8)\n",
    "        \n",
    "        ## 1_将目标值和特征值切片切开\n",
    "        label = tf.slice(decoded, [0], [self.label_bytes])\n",
    "        image = tf.slice(decoded, [1], [self.image_bytes])\n",
    "        \n",
    "        ## 2_调整图片形状，以符合tensor的输入要求\n",
    "        image_reshaped = tf.reshape(image, shape=[self.channels,self.height,self.width])\n",
    "        \n",
    "        ## 3_转置 将图片调整为 HWC\n",
    "        image_transposed = tf.transpose(image_reshaped,[1,2,0])\n",
    "        print(\"image_reshaped:{}\\n image_tansposed:{}\\n\".format(image_reshaped,image_transposed))\n",
    "        \n",
    "        ## 4_调整图像类型 uint8->float32\n",
    "        image_cast = tf.cast(image_transposed, tf.float32)\n",
    "        \n",
    "        # 3.批处理\n",
    "        label_batch,image_batch = tf.compat.v1.train.batch([label,image_cast],batch_size=100,num_threads=1,capacity=100)\n",
    "        print(label_batch)\n",
    "        \n",
    "        # 开启会话\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            # 开启线程\n",
    "            coord = tf.compat.v1.train.Coordinator()\n",
    "            threads = tf.compat.v1.train.start_queue_runners(sess=sess, coord=coord)\n",
    "            \n",
    "            key_new, value_new, decoded_new, label_new, image_new,image_reshaped_new,image_transposed_new = sess.run(\n",
    "                [key, value, decoded, label, image, image_reshaped, image_transposed]\n",
    "            )\n",
    "            label_value, image_value = sess.run([label_batch, image_batch])\n",
    "            print(\"decoded_new:\\n\",decoded_new)\n",
    "            \n",
    "            # 回收线程\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "            \n",
    "        return None\n",
    "        \n",
    "file_name = os.listdir(\"D:/Project/Data/cifar-10-bin\")\n",
    "# 构建文件名路径列表\n",
    "file_list = [os.path.join(\"D:/Project/Data/cifar-10-bin/\", file) for file in file_name if file[-3:] == \"bin\"]\n",
    "\n",
    "# 实例化Cifar\n",
    "cifar = Cifar()\n",
    "cifar.read_and_decode(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.slice(\n",
    "    input_, begin, size, name=None\n",
    ")\n",
    "\n",
    "- input_: A Tensor.\n",
    "- begin: An int32 or int64 Tensor.\n",
    "- size: An int32 or int64 Tensor.\n",
    "- name: A name for the operation (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 TFRecords文件\n",
    "\n",
    "### 3.4.1 什么是TFRecords文件？\n",
    "是一种二进制文件，虽然它不如其他格式的数据好理解，但是它能更好的利用内容，并且不需要单独的标签，即样本和样本标签是绑定在一起的。\n",
    "\n",
    "使用步骤：\n",
    "- 1）获取数据\n",
    "- 2）将数据填入到example协议内存块（protocol buffer）\n",
    "- 3）将协议内存块序列化为字符串，并且通过tf.python_io.TFRecordWriter写入到TFRecord文件中。\n",
    "- 4）开启会话\n",
    "- 5）手动开启线程\n",
    "\n",
    "### 3.4.2 Example 结构解析\n",
    "cifar10\n",
    "  - 特征值 - image - 3072个字节\n",
    "  - 目标值 - label - 1个字节\n",
    "  \n",
    "  example = tf.compat.v1.train.Example(features=tf.compat.v1.train.Features(feature={\n",
    "                    \"image\":tf.compat.v1.train.Feature(bytes_list=tf.compat.v1.train.BytesList(value=[image])),\n",
    "                    \"label\":tf.compat.v1.train.Feature(int64_list=tf.compat.v1.train.Int64List(value=[label])),\n",
    "                }))\n",
    "\n",
    "\n",
    "example结构：\n",
    "```python\n",
    "features {\n",
    "  feature {\n",
    "    key: \"feature0\"\n",
    "    value {\n",
    "      int64_list {\n",
    "        value: 0\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  feature {\n",
    "    key: \"feature1\"\n",
    "    value {\n",
    "      int64_list {\n",
    "        value: 4\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  feature {\n",
    "    key: \"feature2\"\n",
    "    value {\n",
    "      bytes_list {\n",
    "        value: \"goat\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  feature {\n",
    "    key: \"feature3\"\n",
    "    value {\n",
    "      float_list {\n",
    "        value: 0.9876000285148621\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.train.Example()\n",
    "  - 写入tfrecords文件\n",
    "  - features：tf.train.Features类型的特征实例\n",
    "- tf.train.Features()\n",
    "  - 构建每个样本的信息键值对\n",
    "  - features：字典数据，key为要保存的名字\n",
    "  - value为tf.train.Feature实例\n",
    "  - return：Features类型\n",
    "- tf.train.Feature()\n",
    "  - options：例如\n",
    "    - bytes_list = tf.train.BytesList(value=[Bytes])\n",
    "    - int64_list = tf.train.int64List(value[Value])\n",
    "  - 支持输入的类型如下：\n",
    "  - tf.train.int64List(value=[Value])\n",
    "  - tf.train.BytesList(value=[Bytes])\n",
    "  - tf.train.FloatList(value=[Value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 CIFAR10数据存入TFRecords文件\n",
    "\n",
    "- 构造存储实例，tf.python_io.TFRecordWriter(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-1c74ce24d2fc>:23: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-1-1c74ce24d2fc>:27: FixedLengthRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "key:\n",
      "Tensor(\"ReaderReadV2:0\", shape=(), dtype=string)\n",
      " value:\n",
      "Tensor(\"ReaderReadV2:1\", shape=(), dtype=string)\n",
      "\n",
      "image_reshaped:Tensor(\"Reshape:0\", shape=(3, 32, 32), dtype=uint8)\n",
      " image_tansposed:Tensor(\"transpose:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-1c74ce24d2fc>:49: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "Tensor(\"batch:0\", shape=(100, 1), dtype=uint8)\n",
      "WARNING:tensorflow:From <ipython-input-1-1c74ce24d2fc>:56: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "decoded_new:\n",
      " [  2  30  45 ... 106  99 147]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import os\n",
    "\n",
    "\n",
    "class Cifar(object):\n",
    "    def __init__(self):\n",
    "        # 初始化操作\n",
    "        self.height = 32\n",
    "        self.width = 32\n",
    "        self.channels = 3\n",
    "        \n",
    "        # 字节数\n",
    "        self.image_bytes = self.height * self.width * self.channels\n",
    "        self.label_bytes = 1\n",
    "        self.all_bytes = self.label_bytes + self.image_bytes\n",
    "        \n",
    "    def read_binary(self):\n",
    "        # 1.构造文件名队列\n",
    "        file_name = os.listdir(\"D:/Project/Data/cifar-10-bin\")\n",
    "        # 构建文件名路径列表\n",
    "        file_list = [os.path.join(\"D:/Project/Data/cifar-10-bin/\", file) for file in file_name if file[-3:] == \"bin\"]\n",
    "        file_queue = tf.compat.v1.train.string_input_producer(file_list)\n",
    "        \n",
    "        # 2.读取与解码\n",
    "        ## 读取阶段\n",
    "        reader = tf.compat.v1.FixedLengthRecordReader(self.all_bytes)\n",
    "        key,value = reader.read(file_queue)\n",
    "        print(\"key:\\n{}\\n value:\\n{}\\n\".format(key,value))\n",
    "        \n",
    "        ## 解码阶段\n",
    "        decoded = tf.compat.v1.decode_raw(value, tf.uint8)\n",
    "        \n",
    "        ## 1_将目标值和特征值切片切开\n",
    "        label = tf.slice(decoded, [0], [self.label_bytes])\n",
    "        image = tf.slice(decoded, [1], [self.image_bytes])\n",
    "        \n",
    "        ## 2_调整图片形状，以符合tensor的输入要求\n",
    "        image_reshaped = tf.reshape(image, shape=[self.channels,self.height,self.width])\n",
    "        \n",
    "        ## 3_转置 将图片调整为 HWC\n",
    "        image_transposed = tf.transpose(image_reshaped,[1,2,0])\n",
    "        print(\"image_reshaped:{}\\n image_tansposed:{}\\n\".format(image_reshaped,image_transposed))\n",
    "        \n",
    "        ## 4_调整图像类型 uint8->float32\n",
    "        image_cast = tf.cast(image_transposed, tf.float32)\n",
    "        \n",
    "        # 3.批处理\n",
    "        label_batch,image_batch = tf.compat.v1.train.batch([label,image_cast],batch_size=100,num_threads=1,capacity=100)\n",
    "        print(label_batch)\n",
    "        \n",
    "        # 开启会话\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            # 开启线程\n",
    "            coord = tf.compat.v1.train.Coordinator()\n",
    "            threads = tf.compat.v1.train.start_queue_runners(sess=sess, coord=coord)\n",
    "            \n",
    "            key_new, value_new, decoded_new, label_new, image_new,image_reshaped_new,image_transposed_new = sess.run(\n",
    "                [key, value, decoded, label, image, image_reshaped, image_transposed]\n",
    "            )\n",
    "            label_value, image_value = sess.run([label_batch, image_batch])\n",
    "            print(\"decoded_new:\\n\",decoded_new)\n",
    "            \n",
    "            # 回收线程\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "            \n",
    "        return image_value, label_value\n",
    "    \n",
    "    def write_to_tfrecords(self, image_batch, label_batch):\n",
    "        \"\"\"\n",
    "        将样本的特征值写入TFRecords文件\n",
    "        \"\"\"\n",
    "        with tf.compat.v1.python_io.TFRecordWriter(\"cifar10.tfrecords\") as writer:\n",
    "            # 循环构造example对象，并序列化写入文件\n",
    "            for i in range(100):\n",
    "                image = image_batch[i].tostring() #bytes类型\n",
    "                label = label_batch[i][0] #取出整型单值\n",
    "                #print(\"label:{}\\n image:{}\".format(label,image))\n",
    "                example = tf.compat.v1.train.Example(features=tf.compat.v1.train.Features(feature={\n",
    "                    \"image\":tf.compat.v1.train.Feature(bytes_list=tf.compat.v1.train.BytesList(value=[image])),\n",
    "                    \"label\":tf.compat.v1.train.Feature(int64_list=tf.compat.v1.train.Int64List(value=[label])),\n",
    "                }))\n",
    "                #example.SerializeToString()\n",
    "                # 将序列化后的example下入example文件\n",
    "                writer.write(example.SerializeToString())\n",
    "                                                                      \n",
    "        return None\n",
    "\n",
    "    \n",
    "    def read_tfrecords(self):\n",
    "        # 1.构造文件名队列\n",
    "        file_queue = tf.compat.v1.train.string_input_producer([\"cifar10.tfrecords\"])\n",
    "        \n",
    "        # 2.读取与解码\n",
    "        reader = tf.compat.v1.TFRecordReader()\n",
    "        key,value = reader.read(file_queue)\n",
    "        \n",
    "        # 解析 example\n",
    "        feature = tf.compat.v1.parse_single_example(value, features={\n",
    "            \"image\":tf.compat.v1.FixedLenFeature([], tf.string),\n",
    "            \"label\":tf.compat.v1.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "        image = feature[\"image\"]\n",
    "        label = feature[\"label\"]\n",
    "        \n",
    "        ## 解码\n",
    "        image_decoded = tf.compat.v1.decode_raw(image, tf.uint8)\n",
    "        print(\"image_decoded:\",image_decoded)\n",
    "        \n",
    "        ## 图像形状调整\n",
    "        image_reshaped = tf.compat.v1.reshape(image_decoded, [self.height, self.width, self.channels])\n",
    "        \n",
    "        # 3.构造批处理队列\n",
    "        image_batch,label_batch = tf.compat.v1.train.batch([image_reshaped, label], batch_size=100, num_threads=2, capacity=100)\n",
    "        \n",
    "        \n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            \n",
    "            # 开启线程\n",
    "            coord = tf.compat.v1.train.Coordinator()\n",
    "            threads = tf.compat.v1.train.start_queue_runners(sess=sess, coord=coord)\n",
    "            \n",
    "            image_value, label_value = sess.run([image_batch, label_batch])\n",
    "            print(\"image_value:\\n\",image_value)\n",
    "            \n",
    "            # 回收线程\n",
    "            coord.requset_stop()\n",
    "            coord.join(threads)\n",
    "            \n",
    "        return None\n",
    "\n",
    "# 实例化Cifar\n",
    "cifar = Cifar()\n",
    "image_value, label_value = cifar.read_binary()\n",
    "cifar.write_to_tfrecords(image_value, label_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-1c74ce24d2fc>:96: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "image_decoded: Tensor(\"DecodeRaw_1:0\", shape=(None,), dtype=uint8)\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Input to reshape is a tensor with 12288 values, but the requested shape has 3072\n",
      "\t [[{{node Reshape_1}}]]\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "FIFOQueue '_7_batch_1/fifo_queue' is closed and has insufficient elements (requested 100, current size 0)\n\t [[node batch_1 (defined at <ipython-input-1-1c74ce24d2fc>:115) ]]\n\nOriginal stack trace for 'batch_1':\n  File \"C:\\anaconda3\\envs\\keras\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-9530ee91eec1>\", line 2, in <module>\n    cifar2.read_tfrecords()\n  File \"<ipython-input-1-1c74ce24d2fc>\", line 115, in read_tfrecords\n    image_batch,label_batch = tf.compat.v1.train.batch([image_reshaped, label], batch_size=100, num_threads=2, capacity=100)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py\", line 1020, in batch\n    name=name)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py\", line 789, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\ops\\data_flow_ops.py\", line 488, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_data_flow_ops.py\", line 3536, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1351\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1352\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1444\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1445\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: FIFOQueue '_7_batch_1/fifo_queue' is closed and has insufficient elements (requested 100, current size 0)\n\t [[{{node batch_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9530ee91eec1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcifar2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCifar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcifar2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_tfrecords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-1c74ce24d2fc>\u001b[0m in \u001b[0;36mread_tfrecords\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mthreads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m             \u001b[0mimage_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image_value:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 960\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    961\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1183\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1184\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1361\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1384\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1386\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: FIFOQueue '_7_batch_1/fifo_queue' is closed and has insufficient elements (requested 100, current size 0)\n\t [[node batch_1 (defined at <ipython-input-1-1c74ce24d2fc>:115) ]]\n\nOriginal stack trace for 'batch_1':\n  File \"C:\\anaconda3\\envs\\keras\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-9530ee91eec1>\", line 2, in <module>\n    cifar2.read_tfrecords()\n  File \"<ipython-input-1-1c74ce24d2fc>\", line 115, in read_tfrecords\n    image_batch,label_batch = tf.compat.v1.train.batch([image_reshaped, label], batch_size=100, num_threads=2, capacity=100)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py\", line 1020, in batch\n    name=name)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py\", line 789, in _batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\ops\\data_flow_ops.py\", line 488, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_data_flow_ops.py\", line 3536, in queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 742, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3322, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1756, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "cifar2 = Cifar()\n",
    "cifar2.read_tfrecords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 读取TFRecords文件API\n",
    "- tf.parse_single_example(serialized, features=None,name=None)\n",
    "  - 解析一个单一的Example原型。\n",
    "  - serialized：标量字符串Tensor，一个序列化的Example。\n",
    "  - features：dict字典数据，键为读取的名字，值为FixedLenFeature。\n",
    "  - return：一个键值对组成的字典，键为读取的名字。\n",
    "  \n",
    "- tf.FixedLenFeature(shape,dtype)\n",
    "  - shape：输入数据的形状，一般不指定，为空列表。\n",
    "  - dtype：输入数据的类型。类型只能是float32，int64，string。\n",
    "\n",
    "步骤：\n",
    "- 1）构造文件名队列\n",
    "- 2）读取和解码\n",
    "  - 读取\n",
    "  解析example\n",
    "  feature = tf.compat.v1.parse_single_example(values, features={\n",
    "  \"image\":tf.compat.v1.FixedLenFeature([], tf.string)\n",
    "  \"label\":tf.compat.v1.FixedLenFeature([], tf.int64)\n",
    "  })\n",
    "  image = feature[\"image\"]\n",
    "  label = feature[\"label\"]\n",
    "  \n",
    "  - 解码\n",
    "- 3）构造批处理队列\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
