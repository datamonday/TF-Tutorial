{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-dev20200429'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ds = tf.data.Dataset.range(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24 25 26 27 28 29]\n",
      "[30 31 32 33 34 35 36 37 38 39]\n",
      "[40 41 42 43 44 45 46 47 48 49]\n"
     ]
    }
   ],
   "source": [
    "# 将数据生成batch_size=10的批数据。其中，drop_remainder 表示\n",
    "# 在batch_size不足批大小的情况下是否删除该批次数据；默认不删除较小的批次。\n",
    "batches = range_ds.batch(10, drop_remainder=True)\n",
    "\n",
    "# 从批次数据中，取出五个批次并打印\n",
    "for batch in batches.take(5):\n",
    "    print(batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]  =>  [8 9]\n",
      "[10 11 12 13 14 15 16 17]  =>  [18 19]\n",
      "[20 21 22 23 24 25 26 27]  =>  [28 29]\n"
     ]
    }
   ],
   "source": [
    "def dense_1_step(batch):\n",
    "    # 将单变量时间序列数据与预测标签数据匹配\n",
    "    return batch[:-2], batch[8:]\n",
    "\n",
    "# map方法将所有批次数据实现数据与标签的匹配\n",
    "predict_dense_1_step = batches.map(dense_1_step) \n",
    "\n",
    "# 打印三个匹配好的样本\n",
    "for features, label in predict_dense_1_step.take(3):\n",
    "    print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]  =>  [10 11 12 13 14]\n",
      "[15 16 17 18 19 20 21 22 23 24]  =>  [25 26 27 28 29]\n",
      "[30 31 32 33 34 35 36 37 38 39]  =>  [40 41 42 43 44]\n"
     ]
    }
   ],
   "source": [
    "batches = range_ds.batch(15, drop_remainder=True)\n",
    "\n",
    "def label_next_5_steps(batch):\n",
    "    return (batch[:-5],   # 一个批次内前十个采样点作为输入\n",
    "            batch[-5:])   # 一个批次内后五个采样点作为标签\n",
    "\n",
    "predict_5_steps = batches.map(label_next_5_steps)\n",
    "\n",
    "for features, label in predict_5_steps.take(3):\n",
    "    print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]  =>  [20 21 22 23 24]\n",
      "[10 11 12 13 14 15 16 17 18 19]  =>  [30 31 32 33 34]\n",
      "[20 21 22 23 24 25 26 27 28 29]  =>  [40 41 42 43 44]\n"
     ]
    }
   ],
   "source": [
    "feature_length = 10 # 窗口宽度\n",
    "label_length = 5 # 预测输出的长度\n",
    "\n",
    "features = range_ds.batch(feature_length, drop_remainder=True)\n",
    "# skip() 方法表示取一个批次之后的数据\n",
    "# labels[:-5] 表示截取该批次的前五个采样数据\n",
    "labels = range_ds.batch(feature_length).skip(2).map(lambda labels: labels[:-5])\n",
    "\n",
    "# zip 方法实现将样本数据与样本标签匹配\n",
    "predict_5_steps = tf.data.Dataset.zip((features, labels))\n",
    "\n",
    "for features, label in predict_5_steps.take(3):\n",
    "    print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, None, 1, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[1, 2, 3]\n",
      "[2, 3, 4]\n",
      "[3, 4, 5]\n",
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, 1, 1, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[2, 3, 4]\n",
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, 2, 1, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, 3, 1, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, None, 1, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, None, 2, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, None, 3, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[1, 2, 3]\n",
      "[2, 3, 4]\n",
      "[3, 4, 5]\n",
      "[4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, 1, 1, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4]\n",
      "[1, 3, 5]\n",
      "[2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, 1, 2, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(7).window(3, 1, 3, True) \n",
    "for window in dataset: \n",
    "    print(list(window.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "nested = {'a':[1, 2, 3, 4], 'b':[6, 7, 8, 9]}\n",
    "dataset = tf.data.Dataset.from_tensor_slices(nested).window(2,2,1,True) \n",
    "for window in dataset: \n",
    "    def to_numpy(ds): \n",
    "        return list(ds.as_numpy_iterator()) \n",
    "    print(to_numpy(window['a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002B6EAFFB3A8> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "for x in windows.flat_map(lambda x: x).take(30):\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002B6EAFFB3A8> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "for x in windows.flat_map(lambda x: x).take(30):\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "0 1 2 3 4 1 2 3 4 5 2 3 4 5 6 3 4 5 6 7 4 5 6 7 8 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "windows = range_ds.window(window_size, shift=1)\n",
    "for x in windows.flat_map(lambda x: x).take(30):\n",
    "    print(x.numpy(), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[1 2 3 4 5]\n",
      "[2 3 4 5 6]\n",
      "[3 4 5 6 7]\n",
      "[4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "def sub_to_batch(sub):\n",
    "    return sub.batch(window_size, drop_remainder=True)\n",
    "\n",
    "for example in windows.flat_map(sub_to_batch).take(5):\n",
    "    print(example.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n",
    "    windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "\n",
    "    def sub_to_batch(sub):\n",
    "        return sub.batch(window_size, drop_remainder=True)\n",
    "\n",
    "    windows = windows.flat_map(sub_to_batch)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  4  6  8 10 12 14 16 18]\n",
      "[ 1  3  5  7  9 11 13 15 17 19]\n",
      "[ 2  4  6  8 10 12 14 16 18 20]\n",
      "[ 3  5  7  9 11 13 15 17 19 21]\n",
      "[ 4  6  8 10 12 14 16 18 20 22]\n",
      "[ 5  7  9 11 13 15 17 19 21 23]\n",
      "[ 6  8 10 12 14 16 18 20 22 24]\n",
      "[ 7  9 11 13 15 17 19 21 23 25]\n",
      "[ 8 10 12 14 16 18 20 22 24 26]\n",
      "[ 9 11 13 15 17 19 21 23 25 27]\n"
     ]
    }
   ],
   "source": [
    "ds = make_window_dataset(range_ds, window_size=10, shift=1, stride=2)\n",
    "\n",
    "for example in ds.take(10):\n",
    "    print(example.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
